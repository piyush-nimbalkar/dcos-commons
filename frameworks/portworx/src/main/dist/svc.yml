name: {{FRAMEWORK_NAME}}
scheduler:
  principal: {{FRAMEWORK_PRINCIPAL}}
pods:
  portworx:
    user: {{SERVICE_USER}}
    count: {{NODE_COUNT}}
    {{#SECRETS_ENABLED}}
    secrets:
      secrets_username:
        secret: {{SECRETS_DCOS_USERNAME}}
        env-key: DCOS_SECRETS_USERNAME
      secrets_password:
        secret: {{SECRETS_DCOS_PASSWORD}}
        env-key: DCOS_SECRETS_PASSWORD
    {{/SECRETS_ENABLED}}
    resource-sets:
      px-resources:
        cpus: 0.3
        memory: 256
        # Allocate a minimum sized local volume to the tasks so that they are pinned to a node
        volume:
          path: temp
          size: 1
          type: ROOT
        ports:
          api:
            port: {{PORTWORX_START_PORT}}
            vip:
              prefix: api
              port: {{PORTWORX_START_PORT}}
    placement: {{NODE_PLACEMENT}}
    uris:
      - {{SYSCTL_URI}}
    {{#PRE_RESERVED_ROLE}}
    pre-reserved-role: {{PRE_RESERVED_ROLE}}
    {{/PRE_RESERVED_ROLE}}
    tasks:
      install:
        goal: RUNNING
        resource-set: px-resources
        cmd: |
                touch $MESOS_SANDBOX/install-in-progress
                docker pull {{{PORTWORX_IMAGE_NAME}}}

                docker rm -f px_version
                newPxVersion="$(docker run --rm --name px_version --entrypoint /opt/pwx/bin/pxctl {{{PORTWORX_IMAGE_NAME}}} --version) (OCI)"
                if [ $? != 0 ]; then
                    echo 'Error finding portworx version from the given image {{{PORTWORX_IMAGE_NAME}}}'
                    exit 1
                fi

                curPxVersion=$(/opt/pwx/bin/pxctl --version)
                if [[ $curPxVersion != $newPxVersion ]]; then
                    ./sysCtl stop portworx.service

                    set -e
                    docker run --entrypoint /runc-entry-point.sh \
                        --rm -i --name portworx_runc \
                        -v /opt/pwx:/opt/pwx -v /etc/pwx:/etc/pwx \
                        {{{PORTWORX_IMAGE_NAME}}} --debug --upgrade
                    set +e
                fi

                coreos=$(uname -a | grep coreos)

                if [ -z "$coreos" ]; then
                    USR_SRC_MOUNT="-v /usr/src:/usr/src"
                fi

                {{#ETCD_ENABLED}}
                {{#ETCD_PROXY_ENABLED}}
                PORTWORX_KVDB=etcd://etcd-proxy-0-start.${FRAMEWORK_HOST}:{{ETCD_PROXY_ADVERTISE_PORT}}
                {{/ETCD_PROXY_ENABLED}}
                {{^ETCD_PROXY_ENABLED}}
                PORTWORX_KVDB=etcd://etcd-cluster-0-node.${FRAMEWORK_HOST}:{{ETCD_NODE_ADVERTISE_PORT}},etcd://etcd-cluster-1-node.${FRAMEWORK_HOST}:{{ETCD_NODE_ADVERTISE_PORT}},etcd://etcd-cluster-2-node.${FRAMEWORK_HOST}:{{ETCD_NODE_ADVERTISE_PORT}}
                {{/ETCD_PROXY_ENABLED}}
                {{/ETCD_ENABLED}}
                {{^ETCD_ENABLED}}
                PORTWORX_KVDB={{PORTWORX_KVDB_SERVERS}}
                {{/ETCD_ENABLED}}

                {{#INTERNAL_KVDB}}
                KVDB_OPTION="-b"
                {{/INTERNAL_KVDB}}

                if [[ ! -z "${PORTWORX_KVDB// }" ]]; then
                    KVDB_OPTION="-k $PORTWORX_KVDB"
                fi

                startPort={{PORTWORX_START_PORT}}
                if [[ "$startPort" != "9001" ]]; then
                    START_PORT_OPTION="-r $startPort"
                fi

                echo "[Unit]
                    Description=Portworx Container
                    Before=docker.service
                    StartLimitIntervalSec=3600
                    StartLimitInterval=3600
                    StartLimitBurst=10000
                    [Service]
                    StartLimitBurst=10000
                    TimeoutStartSec=0
                    Restart=always
                    ExecStartPre=`which ping` -c 1 master.mesos
                    ExecStartPre=-/opt/pwx/bin/runc delete -f %n
                    ExecStart=/opt/pwx/bin/px-runc run \
                          -v /run/docker/plugins:/run/docker/plugins     \
                          -v /var/lib/mesos:/var/lib/mesos:shared        \
                          -v /var/lib/kubelet:/var/lib/kubelet:shared    \
                          $USR_SRC_MOUNT                                 \
                          {{#NODE_CONTAINER_PARAMETERS}}
                          {{{NODE_CONTAINER_PARAMETERS}}}                \
                          {{/NODE_CONTAINER_PARAMETERS}}
                          {{#SECRETS_ENABLED}}
                          {{#SECRETS_BASE_PATH}}
                          -e DCOS_SECRETS_BASE_PATH={{SECRETS_BASE_PATH}} \
                          {{/SECRETS_BASE_PATH}}
                          -e DCOS_SECRETS_USERNAME=$DCOS_SECRETS_USERNAME \
                          -e DCOS_SECRETS_PASSWORD=$DCOS_SECRETS_PASSWORD \
                          -secret_type dcos \
                          {{/SECRETS_ENABLED}}
                          -name=%n \
                          -c {{PORTWORX_CLUSTER_NAME}} {{{PORTWORX_OPTIONS}}} \
                          $START_PORT_OPTION $KVDB_OPTION
                    KillMode=control-group
                    ExecStop=/opt/pwx/bin/runc kill %n
                    [Install]
                    WantedBy=multi-user.target" > /etc/systemd/system/portworx.service.new

                diff -Z /etc/systemd/system/portworx.service.new /etc/systemd/system/portworx.service
                difference=$?

                set -e
                if [ ! -f /etc/systemd/system/portworx.service ]; then
                    freshInstall="true"
                fi

                mv /etc/systemd/system/portworx.service.new /etc/systemd/system/portworx.service
                ./sysCtl reload

                if [ "$freshInstall" == "true" ]; then
                    ./sysCtl enable portworx.service
                fi
                set +e

                svc_status=$(./sysCtl prop portworx.service | grep UnitFileState | grep "enabled")
                svc_inactive=$(./sysCtl prop portworx.service | grep ActiveState | grep "inactive")
                if [[ ( "$svc_status" != "" ) && \
                      ( "$svc_inactive" != "" || "$difference" -ne 0 || $curPxVersion != $newPxVersion) ]]; then
                    ./sysCtl restart portworx.service
                fi &&
                rm $MESOS_SANDBOX/install-in-progress
                journalctl -afu portworx
        readiness-check:
          cmd: |
               if [ ! -f /etc/systemd/system/portworx.service ]; then
                   exit 1
               fi
               if [ -f $MESOS_SANDBOX/install-in-progress ]; then
                   exit 1
               fi
               svc_status=$(./sysCtl prop portworx.service | grep UnitFileState | grep "enabled")
               set -e
               if [[ "$svc_status" != "" ]]; then
                   /opt/pwx/bin/pxctl -j status | grep status | grep 'STATUS_OK\|STATUS_NOT_IN_QUORUM\|STATUS_NOT_IN_QUORUM_NO_STORAGE'
               fi
          interval: 15
          delay: 10
          timeout: 60
        health-check:
          cmd: |
               if [ ! -f /etc/systemd/system/portworx.service ]; then
                   pkill -fx 'journalctl -afu portworx'
               fi
               svc_status=$(./sysCtl prop portworx.service | grep UnitFileState | grep "enabled")
               if [[ "$svc_status" != "" ]]; then
                   /opt/pwx/bin/pxctl -j status | grep status | grep 'STATUS_OK\|STATUS_NOT_IN_QUORUM\|STATUS_NOT_IN_QUORUM_NO_STORAGE'
                   if [ $? != 0 ]; then
                       /opt/pwx/bin/pxctl status
                       exit 1
                   fi
               fi
          grace-period: 120
          interval: 60
          delay: 0
          timeout: 60
          max-consecutive-failures: 5
  etcd-cluster:
    user: {{SERVICE_USER}}
    count: 3
    image: {{ETCD_IMAGE}}
    placement: {{ETCD_PLACEMENT}}
    {{#PRE_RESERVED_ROLE}}
    pre-reserved-role: {{PRE_RESERVED_ROLE}}
    {{/PRE_RESERVED_ROLE}}
    uris:
      - {{BOOTSTRAP_URI}}
    tasks:
      node:
        goal: RUNNING
        memory: {{ETCD_MEM}}
        cpus: {{ETCD_CPUS}}
        # etcd doesn't like space before flags, so need to put this all on one line
        cmd: >
             ${MESOS_SANDBOX}/bootstrap && /work/bin/etcd --name etcd${POD_INSTANCE_INDEX} --advertise-client-urls http://etcd-cluster-${POD_INSTANCE_INDEX}-node.${FRAMEWORK_HOST}:{{ETCD_NODE_ADVERTISE_PORT}} --listen-client-urls http://0.0.0.0:{{ETCD_NODE_ADVERTISE_PORT}} --initial-advertise-peer-urls http://etcd-cluster-${POD_INSTANCE_INDEX}-node.${FRAMEWORK_HOST}:{{ETCD_NODE_PEER_PORT}} --listen-peer-urls http://0.0.0.0:{{ETCD_NODE_PEER_PORT}} --initial-cluster-token etcd-cluster-${FRAMEWORK_NAME} --initial-cluster etcd0=http://etcd-cluster-0-node.${FRAMEWORK_HOST}:{{ETCD_NODE_PEER_PORT}},etcd1=http://etcd-cluster-1-node.${FRAMEWORK_HOST}:{{ETCD_NODE_PEER_PORT}},etcd2=http://etcd-cluster-2-node.${FRAMEWORK_HOST}:{{ETCD_NODE_PEER_PORT}} --initial-cluster-state new --data-dir $MESOS_SANDBOX/etcd-data
        volume:
          path: "etcd-data"
          type: {{ETCD_DISK_TYPE}}
          size: {{ETCD_DISK_SIZE}}
        ports:
          node-advertise:
            port: {{ETCD_NODE_ADVERTISE_PORT}}
          peer:
            port: {{ETCD_NODE_PEER_PORT}}
        readiness-check:
          cmd: /work/bin/etcdctl --endpoint http://etcd-cluster-${POD_INSTANCE_INDEX}-node.${FRAMEWORK_HOST}:{{ETCD_NODE_ADVERTISE_PORT}} cluster-health
          interval: 5
          delay: 0
          timeout: 60

  etcd-proxy:
    user: {{SERVICE_USER}}
    count: 1
    image: {{ETCD_IMAGE}}
    {{#PRE_RESERVED_ROLE}}
    pre-reserved-role: {{PRE_RESERVED_ROLE}}
    {{/PRE_RESERVED_ROLE}}
    tasks:
      start:
        goal: RUNNING
        memory: 512
        cpus: 0.3
        cmd: /work/bin/etcd --proxy=on --initial-cluster etcd0=http://etcd-cluster-0-node.${FRAMEWORK_HOST}:{{ETCD_NODE_PEER_PORT}},etcd1=http://etcd-cluster-1-node.${FRAMEWORK_HOST}:{{ETCD_NODE_PEER_PORT}},etcd2=http://etcd-cluster-2-node.${FRAMEWORK_HOST}:{{ETCD_NODE_PEER_PORT}} --listen-client-urls http://0.0.0.0:{{ETCD_PROXY_ADVERTISE_PORT}}
        ports:
          proxy-advertise:
            port: {{ETCD_PROXY_ADVERTISE_PORT}}
        readiness-check:
          cmd: /work/bin/etcdctl cluster-health
          interval: 5
          delay: 0
          timeout: 60
  lighthouse:
    user: {{SERVICE_USER}}
    count: 1
    image: {{LIGHTHOUSE_IMAGE}}
    placement: {{LIGHTHOUSE_PLACEMENT}}
    {{#LIGHTHOUSE_PUBLIC_AGENT}}
    pre-reserved-role: slave_public
    {{/LIGHTHOUSE_PUBLIC_AGENT}}
    {{^LIGHTHOUSE_PUBLIC_AGENT}}
    {{#PRE_RESERVED_ROLE}}
    pre-reserved-role: {{PRE_RESERVED_ROLE}}
    {{/PRE_RESERVED_ROLE}}
    {{/LIGHTHOUSE_PUBLIC_AGENT}}
    tasks:
      start:
        goal: RUNNING
        memory: {{LIGHTHOUSE_MEM}}
        cpus: {{LIGHTHOUSE_CPUS}}
        ports:
          http:
            port: {{LIGHTHOUSE_HTTP_PORT}}
            advertise: true
        volume:
          path: "lh-data"
          type: ROOT
          size: 100
        cmd: |
            clusteruuid=$(LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu curl -s http://api.$FRAMEWORK_VIP_HOST:{{PORTWORX_START_PORT}}/config | jq -r '.clusteruuid')

            if [ ! -f $MESOS_SANDBOX/lh-data/lh/config.yaml ]; then
              mkdir -p $MESOS_SANDBOX/lh-data/lh
              echo "ADMIN_USER: {{LIGHTHOUSE_ADMIN_USER}}
            ADMIN_PASSWORD: \$2y\$10\$HeU6ErdL9KL0oLixfBSFausJ0P9FoYPYsRab7FxhJ.AcZGUzkRp3O
            servercert: '{{LIGHTHOUSE_SERVER_CERT}}'
            serverkey: '{{LIGHTHOUSE_SERVER_KEY}}'
            company:
              name: {{LIGHTHOUSE_COMPANY_NAME}}
              id: '1'
            clusters:
            - uuid: $clusteruuid
              clusterid: {{PORTWORX_CLUSTER_NAME}}
              origendpoint: api.$FRAMEWORK_VIP_HOST
              endpoint: api.$FRAMEWORK_VIP_HOST
              port: '{{PORTWORX_START_PORT}}'
              scheme: http
              clientcertificates:
                key: ''
                cert: ''"> $MESOS_SANDBOX/lh-data/lh/config.yaml
            fi

            chmod 777 $MESOS_SANDBOX

            LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu /entry-point.sh -confpath $MESOS_SANDBOX/lh-data -http_port {{LIGHTHOUSE_HTTP_PORT}}
        readiness-check:
          cmd: |
            status_code=$(LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu curl -s -o /dev/null -I -w %{http_code} http://$TASK_NAME.$FRAMEWORK_HOST:{{LIGHTHOUSE_HTTP_PORT}}/login)
            if [[ "$status_code" != 200 ]]; then
                exit 1
            fi
          interval: 10
          delay: 0
          timeout: 60
  # Dummy pod with GPU resource so that we also get offers from nodes with GPUs
  dummy-pod:
    user: {{SERVICE_USER}}
    count: 1
    {{#PRE_RESERVED_ROLE}}
    pre-reserved-role: {{PRE_RESERVED_ROLE}}
    {{/PRE_RESERVED_ROLE}}
    tasks:
      start:
        goal: RUNNING
        memory: 512
        cpus: 0.3
        gpus: 1
        cmd: sleep 1
plans:
  deploy:
    strategy: serial
    phases:
      {{#ETCD_ENABLED}}
      etcd-cluster:
        strategy: parallel
        pod: etcd-cluster
        steps:
          - default : [[node]]
      {{#ETCD_PROXY_ENABLED}}
      etcd-proxy:
        strategy: serial
        pod: etcd-proxy
        steps:
          - default : [[start]]
      {{/ETCD_PROXY_ENABLED}}
      {{/ETCD_ENABLED}}
      portworx-install:
        strategy: parallel
        pod: portworx
        steps:
          - default : [[install]]
      {{#LIGHTHOUSE_ENABLED}}
      lighthouse-deploy:
        strategy: serial
        pod: lighthouse
        steps:
          - default : [[start]]
      {{/LIGHTHOUSE_ENABLED}}
  update:
    strategy: serial
    phases:
      {{#ETCD_ENABLED}}
      etcd-cluster:
        strategy: parallel
        pod: etcd-cluster
        steps:
          - default : [[node]]
      {{#ETCD_PROXY_ENABLED}}
      etcd-proxy:
        strategy: serial
        pod: etcd-proxy
        steps:
          - default : [[start]]
      {{/ETCD_PROXY_ENABLED}}
      {{/ETCD_ENABLED}}
      portworx-install:
        strategy: serial
        pod: portworx
        steps:
          - default : [[install]]
      {{#LIGHTHOUSE_ENABLED}}
      lighthouse-deploy:
        strategy: serial
        pod: lighthouse
        steps:
          - default : [[start]]
      {{/LIGHTHOUSE_ENABLED}}
